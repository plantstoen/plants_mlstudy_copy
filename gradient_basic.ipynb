{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "plants-mlstudy",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNYMqzhzrA9mSH5tb72ScwT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plantstoen/plants_mlstudy_copy/blob/master/gradient_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPAJ-wxrqDC3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "88096735-d545-4396-b437-5d6b10969c96"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Data\n",
        "x_data = [1, 2, 3, 4, 5]\n",
        "y_data = [1, 2, 3, 4, 5]\n",
        "\n",
        "# W, b initialize\n",
        "W = tf.Variable(2.9)\n",
        "b = tf.Variable(0.5)\n",
        "\n",
        "learning_rate = 0.01 # learning rate 설정\n",
        "\n",
        "# W, b update\n",
        "for i in range(100):\n",
        "    # Gradient descent\n",
        "    with tf.GradientTape() as tape:\n",
        "        hypothesis = W * x_data + b # hypothesis 정의\n",
        "        cost = tf.reduce_mean(tf.square(hypothesis - y_data)) # 오차제곱합을 Cost Function으로 지정\n",
        "    W_grad, b_grad = tape.gradient(cost, [W, b])\n",
        "    W.assign_sub(learning_rate * W_grad)\n",
        "    b.assign_sub(learning_rate * b_grad)\n",
        "    if i % 10 == 0:\n",
        "      print(\"{:5}|{:10.4f}|{:10.4f}|{:10.6f}\".format(i, W.numpy(), b.numpy(), cost))\n",
        "\n",
        "print()\n",
        "\n",
        "# predict\n",
        "print(W * 5 + b)\n",
        "print(W * 2.5 + b)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    0|    2.4520|    0.3760| 45.660004\n",
            "   10|    1.1036|    0.0034|  0.206336\n",
            "   20|    1.0128|   -0.0209|  0.001026\n",
            "   30|    1.0065|   -0.0218|  0.000093\n",
            "   40|    1.0059|   -0.0212|  0.000083\n",
            "   50|    1.0057|   -0.0205|  0.000077\n",
            "   60|    1.0055|   -0.0198|  0.000072\n",
            "   70|    1.0053|   -0.0192|  0.000067\n",
            "   80|    1.0051|   -0.0185|  0.000063\n",
            "   90|    1.0050|   -0.0179|  0.000059\n",
            "\n",
            "tf.Tensor(5.0066934, shape=(), dtype=float32)\n",
            "tf.Tensor(2.4946523, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp6dltijum1f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "bd7c4124-74ce-4202-dfe8-28eafd9f8d1d"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "data = np.array([\n",
        "    # X1,   X2,    X3,   y\n",
        "    [ 73.,  80.,  75., 152. ],\n",
        "    [ 93.,  88.,  93., 185. ],\n",
        "    [ 89.,  91.,  90., 180. ],\n",
        "    [ 96.,  98., 100., 196. ],\n",
        "    [ 73.,  66.,  70., 142. ]\n",
        "], dtype=np.float32)\n",
        "\n",
        "# slice data\n",
        "X = data[:, :-1]\n",
        "y = data[:, [-1]]\n",
        "\n",
        "W = tf.Variable(tf.random.stateless_uniform([3,1], seed=(2, 3)))\n",
        "b = tf.Variable(tf.random.stateless_uniform([1], seed=(2, 3)))\n",
        "\n",
        "learning_rate = 0.00001\n",
        "\n",
        "# hypothesis, prediction function\n",
        "def predict(X):\n",
        "    return tf.matmul(X, W) + b\n",
        "\n",
        "print(\"epoch | cost\")\n",
        "\n",
        "n_epochs = 2000\n",
        "for i in range(n_epochs+1):\n",
        "    # tf.GradientTape() to record the gradient of the cost function\n",
        "    with tf.GradientTape() as tape:\n",
        "        cost = tf.reduce_mean((tf.square(predict(X) - y)))\n",
        "\n",
        "    # calculates the gradients of the loss\n",
        "    W_grad, b_grad = tape.gradient(cost, [W, b])\n",
        "\n",
        "    # updates parameters (W and b)\n",
        "    W.assign_sub(learning_rate * W_grad)\n",
        "    b.assign_sub(learning_rate * b_grad)\n",
        "    \n",
        "    if i % 100 == 0:\n",
        "        print(\"{:5} | {:10.4f}\".format(i, cost.numpy()))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch | cost\n",
            "    0 |  3041.1384\n",
            "  100 |    11.1633\n",
            "  200 |    10.5845\n",
            "  300 |    10.0362\n",
            "  400 |     9.5168\n",
            "  500 |     9.0248\n",
            "  600 |     8.5588\n",
            "  700 |     8.1173\n",
            "  800 |     7.6992\n",
            "  900 |     7.3030\n",
            " 1000 |     6.9278\n",
            " 1100 |     6.5724\n",
            " 1200 |     6.2357\n",
            " 1300 |     5.9167\n",
            " 1400 |     5.6146\n",
            " 1500 |     5.3284\n",
            " 1600 |     5.0573\n",
            " 1700 |     4.8005\n",
            " 1800 |     4.5572\n",
            " 1900 |     4.3268\n",
            " 2000 |     4.1085\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}